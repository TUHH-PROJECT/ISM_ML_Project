# -*- coding: utf-8 -*-
"""ISM0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-W1DMnoOZCgpZoS-fw2NulI-qrQ6JMmb

**This is our maine file, don't put code in that file unless you are shure it works**. Try new code in your individual file in the folder Google Colab/Work_in_Progress. Then we can update our individual files accordingly to our progress in the main file

**Don't run the code in the first sections.** It is for uploading. Uploading will take more than 1h. Instead use the sections underneath(where it says: start running code here) to load the data fast.

**Loading the trainings data**

Loading the class array
"""

import pandas as pd
import numpy as np
import PIL
from PIL import Image

#Loading the train.txt file and creation of a list, which contains
#the imagenames and a list which contains the classes
train = pd.read_csv("/content/drive/MyDrive/ISM/train.txt", delimiter="\s")
imagenames = train[["Imagename"]]
classes = train[["Class"]]
print(train.shape)

#Creating a output variable in which the 4 classes: normal, COVID,
#pneumonia and Lung_Opacity are translated into integers
label_maping = {
    "Normal": 0,
    "COVID": 1,
    "pneumonia": 2,
    "Lung_Opacity": 3,
}
y = classes["Class"].map(label_maping)

#Creating a Numpy array
y = np.array(y)

#Save the data as a csv file for fast future loading
np.savetxt("y.csv", y, delimiter = ",")

"""Loading the array which contains the pictures in RGB Format"""

#Uploading the training images as numpy arrays in the RGB Format a saving them in one array
#RGB Format: each image is describe by a RowPixel x ColumnPixel x 3 numpy array, where
#each pixel is described by 3 components, namely the strength of red, blue and green in this pixel

#Uploading in 6 steps for savety reasons

help = 0
for i in imagenames["Imagename"][0:3000]:
    if help == 0:
      X1= np.array(Image.open("/content/drive/MyDrive/ISM/train/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      X1 = X1[np.newaxis,:,:,:]
      help = 1
    else:
      im = np.array(Image.open("/content/drive/MyDrive/ISM/train/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      im = im[np.newaxis,:,:,:]
      #Add each new array to the already loaded
      X1 =  np.append(arr=X1, values=im,axis=0)
print(X1.shape)

#Save the loaded trainings data, which was converted to a numpy array for fast future loading
np.save("X1", X1)

help = 0
for i in imagenames["Imagename"][3000:6000]:
    if help == 0:
      X2= np.array(Image.open("/content/drive/MyDrive/ISM/train/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      X2 = X2[np.newaxis,:,:,:]
      help = 1
    else:
      im = np.array(Image.open("/content/drive/MyDrive/ISM/train/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      im = im[np.newaxis,:,:,:]
      #Add each new array to the already loaded
      X2 =  np.append(arr=X2, values=im,axis=0)
print(X2.shape)

#Save the loaded trainings data, which was converted to a numpy array for fast future loading
np.save("X2", X2)

help = 0
for i in imagenames["Imagename"][6000:9000]:
    if help == 0:
      X3= np.array(Image.open("/content/drive/MyDrive/ISM/train/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      X3 = X3[np.newaxis,:,:,:]
      help = 1
    else:
      im = np.array(Image.open("/content/drive/MyDrive/ISM/train/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      im = im[np.newaxis,:,:,:]
      #Add each new array to the already loaded
      X3 =  np.append(arr=X3, values=im,axis=0)
print(X3.shape)

#Save the loaded trainings data, which was converted to a numpy array for fast future loading
np.save("X3", X3)

help = 0
for i in imagenames["Imagename"][9000:12000]:
    if help == 0:
      X4= np.array(Image.open("/content/drive/MyDrive/ISM/train/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      X4 = X4[np.newaxis,:,:,:]
      help = 1
    else:
      im = np.array(Image.open("/content/drive/MyDrive/ISM/train/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      im = im[np.newaxis,:,:,:]
      #Add each new array to the already loaded
      X4 =  np.append(arr=X4, values=im,axis=0)
print(X4.shape)

#Save the loaded trainings data, which was converted to a numpy array for fast future loading
np.save("X4", X4)

help = 0
for i in imagenames["Imagename"][12000:15000]:
    if help == 0:
      X5= np.array(Image.open("/content/drive/MyDrive/ISM/train/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      X5 = X5[np.newaxis,:,:,:]
      help = 1
    else:
      im = np.array(Image.open("/content/drive/MyDrive/ISM/train/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      im = im[np.newaxis,:,:,:]
      #Add each new array to the already loaded
      X5 =  np.append(arr=X5, values=im,axis=0)
print(X5.shape)

#Save the loaded trainings data, which was converted to a numpy array for fast future loading
np.save("X5", X5)

help = 15000
for i in imagenames["Imagename"][15000:]:
    if help == 15000:
      X6= np.array(Image.open("/content/drive/MyDrive/ISM/train/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      X6 = X6[np.newaxis,:,:,:]
      #This file is not a proper png file. It is not loadable
    elif i == "42f115f5-c446-42fe-a87d-fa619f2eedc5.png":
      print("Index of not loadable file: "+str(help)) 
      index_not_loadable = help
    else:
      im = np.array(Image.open("/content/drive/MyDrive/ISM/train/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      im = im[np.newaxis,:,:,:]
      #Add each new array to the already loaded
      X6 =  np.append(arr=X6, values=im,axis=0)
    help = help+1
print(X6.shape)

#Save the loaded trainings data, which was converted to a numpy array for fast future loading
np.save("X6", X6)

#Reload the data, since the session crashed
import numpy as np
X1 = np.load("X1.npy")
X2 = np.load("X2.npy")
X3 = np.load("X3.npy")
X4 = np.load("X4.npy")
X5 = np.load("X5.npy")
X6 = np.load("X6.npy")

#Put the loaded data in one vector: Do it in 2 steps because of the size of the data
X_half = np.append(arr=X1,values=X2,axis=0)
X_half = np.append(arr=X_half,values=X3,axis=0)
X_half = np.append(arr=X_half,values=X4,axis=0)
X_half = np.append(arr=X_half,values=X5,axis=0)
np.save("X_half",X_half)

#Reload the data, since the session crashed
import numpy as np
X_half = np.load("X_half.npy")

X6 = np.load("X6.npy")

#Second step
X = np.append(arr=X_half,values=X6,axis=0)

import os

#Save the loaded trainings data, which was converted to a numpy array for fast future loading
np.save(os.path.join("/content/drive/MyDrive/ISM_Project_Files","X"), X)

#Shape of X
print(X.shape)

#Reload y
y = np.loadtxt("y.csv", delimiter = ",")

#Delete the class of the not loadable file out of y
y = np.delete(y,16192)
print(y.shape)

#Save numpy array y for fast future loading
np.save(os.path.join("/content/drive/MyDrive/ISM_Project_Files","y"), y)

"""**Loading the test data**"""

import os
import pickle
import numpy as np
import PIL
from PIL import Image

#Loading the test data

#Creating a list with all filenames in the folder test
test_names = os.listdir("/content/drive/MyDrive/ISM/test")
#Saving that list for later use
with open("/content/drive/MyDrive/ISM_Project_Files/test_names", "wb") as f:
  pickle.dump(test_names, f)
f.close()
print(test_names)

print(len(test_names))

#Loading the test data in folder test
help = 0
for i in test_names:
    if help == 0:
      test= np.array(Image.open("/content/drive/MyDrive/ISM/test/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      test = test[np.newaxis,:,:,:]
      help = 1
    else:
      im = np.array(Image.open("/content/drive/MyDrive/ISM/test/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      im = im[np.newaxis,:,:,:]
      #Add each new array to the already loaded
      test = np.append(arr=test, values=im,axis=0)
print(test)

print(test.shape)

#Save the loaded test data, which was converted to a numpy array for fast future loading
np.save(os.path.join("/content/drive/MyDrive/ISM_Project_Files","test"), test)

#Loading the mtec test data

#Creating a list with all filenames in the folder mtec_test
mtec_test_names = os.listdir("/content/drive/MyDrive/ISM/mtec_test")
#Saving that list for later use
with open("/content/drive/MyDrive/ISM_Project_Files/mtec_test_names", "wb") as f:
  pickle.dump(mtec_test_names, f)
f.close()
print(len(mtec_test_names))

#Loading the test data in folder mtec_test
help = 0
for i in mtec_test_names:
    if help == 0:
      mtec_test= np.array(Image.open("/content/drive/MyDrive/ISM/mtec_test/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images
      mtec_test = mtec_test[np.newaxis,:,:,:]
      help = 1
    else:
      im = np.array(Image.open("/content/drive/MyDrive/ISM/mtec_test/"+i))
      #Adding a 4th dimension to the array, in this dimension we save the different Images as 299x299x3 arrays
      im = im[np.newaxis,:,:,:]
      #Add each new array to the already loaded
      mtec_test = np.append(arr=mtec_test, values=im,axis=0)
print(mtec_test.shape)

#Save the loaded mtec_test data, which was converted to a numpy array as a numpy array for fast future loading
np.save(os.path.join("/content/drive/MyDrive/ISM_Project_Files","mtec_test"), mtec_test)

#Loading the noisy test data

#Creating a list with all filenames in the folder test_noise
test_noise_names = os.listdir("/content/drive/MyDrive/ISM/test_noise")
print(len(test_noise_names))
#Saving the list of names for later use
with open("/content/drive/MyDrive/ISM_Project_Files/Noisy_test_data/test_noise_names", "wb") as f:
  pickle.dump(test_noise_names, f)
f.close()

#Loading the test data in folder test_noise

#Create a empty list to save the data in: in this case I don't create a numpy array
#since not all noisy images have the same pixel size. So not all images can be
#represented as a 299x299x3 numpy array. In a list data type I can save different
#types of numpy arrays.
test_noise = [0]*4235
#Create a empty list to save the indicies of the wrong sized images
indicies_wrong_size = [0]*283
help = 0
help2 = 0
for i in test_noise_names:
    #Load the images and convert them in a numpy array
    im = np.array(Image.open("/content/drive/MyDrive/ISM/test_noise/"+i))
    #Add each new array to the already loaded arrays
    test_noise[help] = im
    help = help+1

    #Testing if the loaded image has the correct pixel size, since in test_noise
    #a few images have the wrong size
    if im.shape[0] != 299 or im.shape[1] != 299:
      indicies_wrong_size[help2] = help
      help2 = help2+1    
print("Number of wrong sized images: "+str(help2))
print(indicies_wrong_size)

#Save the loaded noisy test data and the array of indices of the wrong sized images
with open("/content/drive/MyDrive/ISM_Project_Files/Noisy_test_data/test_noise", "wb") as f:
  pickle.dump(test_noise, f)
f.close()
with open("/content/drive/MyDrive/ISM_Project_Files/Noisy_test_data/indicies_wrong_size", "wb") as f:
  pickle.dump(indicies_wrong_size, f)
f.close()

"""**Creating a training-verification split**"""

from sklearn.model_selection import train_test_split
import numpy as np
import os

#Loading the trainings data fast
#X contains all training images which where given to us (except one which was not loadable) saved as numpy arrays.
#Each image is describe by a 299x299x3 numpy array, where 299x299 is the pixel size and each pixel is describe by 3
#values namely the strength of Red, Blue and Green in this pixel. The Range is between 0 and 255, where 
#r=255,g=255,b=255 is white and r=0,g=0,b=0 is black
#y gives the class of each image: "Normal": 0, "COVID": 1, "pneumonia": 2, "Lung_Opacity": 3
X = np.load("/content/drive/MyDrive/ISM_Project_Files/Training/X.npy")
y = np.load("/content/drive/MyDrive/ISM_Project_Files/Training/y.npy")

#Inspection of the arrays
print(X.shape)
print(y.shape)

#Further Inspection
num_nor = 0
num_cov = 0
num_pne = 0
num_lun = 0
for int in y:
  if int == 0:
    num_nor = num_nor+1
  if int == 1:
    num_cov = num_cov+1
  if int == 2:
    num_pne = num_pne+1
  if int == 3:
    num_lun = num_lun+1
print("Share of normal in X: "+str(num_nor/16929))
print("Share of COVID in X: "+str(num_cov/16929))
print("Share of pneumonia in X: "+str(num_pne/16929))
print("Share of Lung_Opacity in X: "+str(num_lun/16929))

#Creating a training and verification set
X_train, X_ver, y_train, y_ver = train_test_split(X, y, train_size=0.8)
#Question: Should we save the training-verification split? Otherwise each time 
#we perform the split, there will be a new random split.

#Inspection of the arrays
print("X_train: "+str(X_train.shape))
print("X_ver: "+str(X_ver.shape))
print("y_train: "+str(y_train.shape))
print("y_ver: "+str(y_ver.shape))

#Further Inspection
num_nor = 0
num_cov = 0
num_pne = 0
num_lun = 0
for int in y_train:
  if int == 0:
    num_nor = num_nor+1
  if int == 1:
    num_cov = num_cov+1
  if int == 2:
    num_pne = num_pne+1
  if int == 3:
    num_lun = num_lun+1
print("Share of normal in X_train: "+str(num_nor/13543))
print("Share of COVID in X_train: "+str(num_cov/13543))
print("Share of pneumonia in X_train: "+str(num_pne/13543))
print("Share of Lung_Opacity in X_train: "+str(num_lun/13543))

"""The share of COVID, normal, pneumonia and Lung_Opacity in X_train is equal to the share of the different features in X."""

#Saving the training and verification split
np.save(os.path.join("/content/drive/MyDrive/ISM_Project_Files/Training_Verification_Split","X_train"),X_train )
np.save(os.path.join("/content/drive/MyDrive/ISM_Project_Files/Training_Verification_Split","X_ver"),X_ver )
np.save(os.path.join("/content/drive/MyDrive/ISM_Project_Files/Training_Verification_Split","y_train"),y_train )
np.save(os.path.join("/content/drive/MyDrive/ISM_Project_Files/Training_Verification_Split","y_ver"),y_ver )

"""**Start running the code here**⛹

**Loading the training and verification split**
"""

import numpy as np

X_train = np.load("/content/drive/MyDrive/ISM_Project_Files/Training_Verification_Split/X_train.npy")
X_ver = np.load("/content/drive/MyDrive/ISM_Project_Files/Training_Verification_Split/X_ver.npy")
y_train = np.load("/content/drive/MyDrive/ISM_Project_Files/Training_Verification_Split/y_train.npy")
y_ver = np.load("/content/drive/MyDrive/ISM_Project_Files/Training_Verification_Split/y_ver.npy")

#Inspection of the arrays: For further explanation on the arrays read the part
#where the training and verification split was created
print("X_train: "+str(X_train.shape))
print("X_ver: "+str(X_ver.shape))
print("y_train: "+str(y_train.shape))
print("y_ver: "+str(y_ver.shape))

"""**Loading the test data**"""

import numpy as np
import pickle

#Loading the test data fast
#test is in the same format as X, mtec_test is similar to the fromat of test
#although the images have another size here each image is saved as a 420x560x3 numpy array
#Different from test and mtec_test test_noise is not a 4-dim numpy array, but a list of
#3-dim numpy arrays. The reason for that is, that the images in test_noise don't have the
#same pixel size and therefore can't be stored in a 4-dim numpy array: The indicies of the images
#with a pixel size different from 299x299 are saved in the list indicies_wrong_size
test = np.load("/content/drive/MyDrive/ISM_Project_Files/Test_data/test.npy")
mtec_test = np.load("/content/drive/MyDrive/ISM_Project_Files/mtec_test_data/mtec_test.npy")
with open("/content/drive/MyDrive/ISM_Project_Files/Noisy_test_data/test_noise", "rb") as f:
  test_noise = pickle.load(f)
f.close()
#Load the list indicies_wrong_size
with open("/content/drive/MyDrive/ISM_Project_Files/Noisy_test_data/indicies_wrong_size", "rb") as f:
  indicies_wrong_size = pickle.load(f)
f.close()

#Inspection of the data
print(test.shape)
print(mtec_test.shape)
print(len(test_noise))
print(len(indicies_wrong_size))

#Loading the lists which contain the names of the test data, noisy test data and
#mtec test data
with open("/content/drive/MyDrive/ISM_Project_Files/Test_data/test_names", "rb") as f:
  test_names = pickle.load(f)
f.close()
with open("/content/drive/MyDrive/ISM_Project_Files/Noisy_test_data/test_noise_names", "rb") as f:
  test_noise_names = pickle.load(f)
f.close()
with open("/content/drive/MyDrive/ISM_Project_Files/mtec_test_data/mtec_test_names", "rb") as f:
  mtec_test_names = pickle.load(f)
f.close()

#Inspection of the lists
print(len(test_names))
print(len(test_noise_names))
print(len(mtec_test_names))