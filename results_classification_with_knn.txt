for comparison it is evident that a random classifier would have 25% of accuracy, bc we have 4 classes in the labels

test knn with Basics_features , weights = 'distance', and with RobustScaler
  with the 6 features : 66.33 % with k = 9

test knn with Shearlet_features , weights = 'uniform', and with RobustScaler
  with the 6 features : 49.05 % with k = 282

test knn with Wavelet_features (HL,HH,LH for energy and entropy) , weights = 'distance', and with RobustScaler
  with the 6 features : 56.05 % with k = 16

test knn with Wavelet_features (all basics features in HL) , weights = 'distance', and with RobustScaler
  with the 6 features : 57.76 % with k = 21

test knn with HU moments , weights = 'distance', and with RobustScaler
  0.622 accuracy for k = 19

test knn with local binnary pattern , weights = 'distance', and with RobustScaler
  0.714 accuracy for k = 29

conclusion :
  the best prediction is 71 % with LBP, robustscaler have been used


sources of information :
    https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn
    https://scikit-learn.org/stable/modules/neighbors.html
